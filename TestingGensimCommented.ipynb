{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `collection.py`\n",
    "\n",
    "The following tutorial shows how to use the collection module of Dariah-Topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prearrangement\n",
    "----\n",
    "First you need to import the collection module so your ipython notebook has access to its functions and classes.\n",
    "As second step we set paths for a test corpus consisting of plain text files and one consisting of annotated text preprocessed with several NLP-Tools in form of csv files (if you have questions concerning the format go to: https://github.com/DARIAH-DE/DARIAH-DKPro-Wrapper/blob/master/doc/tutorial.adoc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_txt = \"corpus_txt\"\n",
    "path_csv = \"corpus_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating list of filenames (plain text and csv files)\n",
    "----\n",
    "The following function is used to normalize path names so non-uniform text files will be processable by the module. It is possible to add an additional argument \"ext\" where you can specify an extension ('csv' in this case). The CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_txt\\\\Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt\\\\Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt\\\\Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt\\\\Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt\\\\Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_txt = collection.create_document_list(path_txt)\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_csv\\\\Doyle_AStudyinScarlet.txt.csv',\n",
       " 'corpus_csv\\\\Doyle_TheHoundoftheBaskervilles.txt.csv',\n",
       " 'corpus_csv\\\\Doyle_TheSignoftheFour.txt.csv',\n",
       " 'corpus_csv\\\\Howard_GodsoftheNorth.txt.csv',\n",
       " 'corpus_csv\\\\Howard_SchadowsinZamboula.txt.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_csv = collection.create_document_list(path_csv, 'csv')\n",
    "doclist_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the corpora\n",
    "----\n",
    "By using the \"read\\_from\\_\"-functions we create a generator object which provides a memory efficient way to handle bigger corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_txt = collection.read_from_txt(doclist_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_csv = collection.read_from_csv(doclist_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Segmenting text\n",
    "----\n",
    "An important part of pre-processing in Topic modelling is segmenting the the texts in 'chunks'. The arguments of the function are for the targeted corpus and the size of the 'chunks' in words. Depending on the languange and type of text results can vary widely in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A SCANDAL IN BOHEMIA\\n\\nA. CONAN DOYLE\\n\\n\\nI\\n\\nTo Sherlock Holmes she is always _the_ woman. I have seldom heard him\\nmention her under any other name. In his eyes she eclipses and\\npredominates the whole of her sex. It was not that he felt any emotion\\nakin to love for Irene Adler. All emotions, and that one particularly,\\nwere abhorrent to his cold, precise but admirably balanced mind. He was,\\nI take it, the most perfect reasoning and observing machine that the\\nworld has seen; but as a lover, he would have placed himself in a false\\nposition. He never spoke of the softer passions, save with a gibe and a\\nsneer. They were admirable things for the observer--excellent for\\ndrawing the veil from men's motives and actions. But for the trained\\nreasoner to admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a distracting factor which might\\nthrow a doubt upon all his mental results. Grit in a sensitive\\ninstrument, or a crack in one of his own high-power lenses, w\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = collection.segmenter(corpus_txt, 1000)\n",
    "next(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Filtering text using POS-Tags\n",
    "----\n",
    "Another way to preprocess the text is by filtering by POS-Tags and using lemmata (in this case only adjectives, verbs and nouns are filterable). The annotated csv-file we provide in this example is already enriched with this kind of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107     infrequent\n",
       "147           fine\n",
       "149          thick\n",
       "175          broad\n",
       "225          solid\n",
       "291          least\n",
       "330    unfortunate\n",
       "344     accidental\n",
       "390     successful\n",
       "392        elderly\n",
       "Name: Lemma, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = collection.filter_POS_tags(corpus_csv)\n",
    "next(lemmas)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Visualization\n",
    "----\n",
    "Simple get-functions are implemented for visualization tasks. In this case the get_labels-function extracts the titles of the corpus files we loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doyle_AScandalinBohemia.txt',\n",
       " 'Doyle_AStudyinScarlet.txt',\n",
       " 'Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'Doyle_TheSignoftheFour.txt',\n",
       " 'Howard_GodsoftheNorth.txt',\n",
       " 'Howard_SchadowsinZamboula.txt',\n",
       " 'Howard_ShadowsintheMoonlight.txt',\n",
       " 'Howard_TheDevilinIron.txt',\n",
       " 'Kipling_TheEndofthePassage.txt',\n",
       " 'Kipling_TheJungleBook.txt',\n",
       " 'Kipling_ThyServantaDog.txt',\n",
       " 'Lovecraft_AttheMountainofMadness.txt',\n",
       " 'Lovecraft_TheShunnedHouse.txt',\n",
       " 'Poe_EurekaAProsePoem.txt',\n",
       " 'Poe_TheCaskofAmontillado.txt',\n",
       " 'Poe_TheMasqueoftheRedDeath.txt',\n",
       " 'Poe_ThePurloinedLetter.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = collection.get_labels(doclist_txt)\n",
    "list(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
