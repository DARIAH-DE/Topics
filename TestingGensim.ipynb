{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `collection.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_txt = \"corpus\"\n",
    "path_csv = \"corpus_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus/Doyle_AScandalinBohemia.txt',\n",
       " 'corpus/Doyle_AStudyinScarlet.txt',\n",
       " 'corpus/Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus/Doyle_TheSignoftheFour.txt',\n",
       " 'corpus/Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_txt = collection.create_document_list(path_txt)\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_document_list in module collection:\n",
      "\n",
      "create_document_list(path, ext='.txt')\n",
      "    Creates a list of files with their full path.\n",
      "    \n",
      "    Args:\n",
      "        path (str): Path to folder, e.g. '/tmp/corpus'.\n",
      "        suffix (str): File extension, e.g. '.csv'. Defaults to '.txt'.\n",
      "    \n",
      "    Returns:\n",
      "        list[str]: List of files with full path.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(collection.create_document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doclist': ['corpus/Doyle_AScandalinBohemia.txt',\n",
       "  'corpus/Doyle_AStudyinScarlet.txt',\n",
       "  'corpus/Doyle_TheHoundoftheBaskervilles.txt',\n",
       "  'corpus/Doyle_TheSignoftheFour.txt',\n",
       "  'corpus/Howard_GodsoftheNorth.txt',\n",
       "  'corpus/Howard_SchadowsinZamboula.txt',\n",
       "  'corpus/Howard_ShadowsintheMoonlight.txt',\n",
       "  'corpus/Howard_TheDevilinIron.txt',\n",
       "  'corpus/Kipling_TheEndofthePassage.txt',\n",
       "  'corpus/Kipling_TheJungleBook.txt',\n",
       "  'corpus/Kipling_ThyServantaDog.txt',\n",
       "  'corpus/Lovecraft_AttheMountainofMadness.txt',\n",
       "  'corpus/Lovecraft_TheShunnedHouse.txt',\n",
       "  'corpus/Poe_EurekaAProsePoem.txt',\n",
       "  'corpus/Poe_TheCaskofAmontillado.txt',\n",
       "  'corpus/Poe_TheMasqueoftheRedDeath.txt',\n",
       "  'corpus/Poe_ThePurloinedLetter.txt']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = collection.ReadFromTXT(doclist_txt)\n",
    "corpus.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'STUDY', 'IN', 'SCARLET.', 'By', 'A.', 'Conan']\n",
      "1000\n",
      "['to', 'go', 'halves', 'with', 'him', 'in', 'some']\n",
      "1000\n",
      "['small', 'quantity', 'of', 'blood', 'to', 'a', 'litre']\n",
      "1000\n",
      "['large', 'airy', 'sitting-room,', 'cheerfully', 'furnished,', 'and', 'illuminated']\n",
      "1000\n",
      "['the', 'moon', 'it', 'would', 'not', 'make', 'a']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "\n",
    "for document in list(corpus):\n",
    "   segments.append(collection.Segmenter(document, 1000))\n",
    "\n",
    "for s in list(segments[1])[:5]:\n",
    "    print(s[:7])\n",
    "    print(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste mit CSV-Dateien erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_csv/Doyle_AStudyinScarlet.txt.csv',\n",
       " 'corpus_csv/Doyle_TheHoundoftheBaskervilles.txt.csv',\n",
       " 'corpus_csv/Doyle_TheSignoftheFour.txt.csv',\n",
       " 'corpus_csv/Howard_GodsoftheNorth.txt.csv',\n",
       " 'corpus_csv/Howard_SchadowsinZamboula.txt.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_csv = collection.create_document_list(path_csv, ext='.csv')\n",
    "doclist_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POS-Tags ausw√§hlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['ParagraphId', 'TokenId', 'Lemma', 'CPOS', 'NamedEntity'],\n",
       " 'doc': Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       " 'files': ['corpus_csv/Doyle_AStudyinScarlet.txt.csv',\n",
       "  'corpus_csv/Doyle_TheHoundoftheBaskervilles.txt.csv',\n",
       "  'corpus_csv/Doyle_TheSignoftheFour.txt.csv',\n",
       "  'corpus_csv/Howard_GodsoftheNorth.txt.csv',\n",
       "  'corpus_csv/Howard_SchadowsinZamboula.txt.csv',\n",
       "  'corpus_csv/Howard_ShadowsintheMoonlight.txt.csv',\n",
       "  'corpus_csv/Howard_TheDevilinIron.txt.csv',\n",
       "  'corpus_csv/Kipling_TheEndofthePassage.txt.csv',\n",
       "  'corpus_csv/Kipling_TheJungleBook.txt.csv',\n",
       "  'corpus_csv/Kipling_ThyServantaDog.txt.csv',\n",
       "  'corpus_csv/Lovecraft_AttheMountainofMadness.txt.csv',\n",
       "  'corpus_csv/Lovecraft_TheShunnedHouse.txt.csv',\n",
       "  'corpus_csv/Poe_EurekaAProsePoem.txt.csv',\n",
       "  'corpus_csv/Poe_TheCaskofAmontillado.txt.csv',\n",
       "  'corpus_csv/Poe_TheMasqueoftheRedDeath.txt.csv',\n",
       "  'corpus_csv/Poe_ThePurloinedLetter.txt.csv'],\n",
       " 'labels': [],\n",
       " 'pos_tags': ['ADJ', 'V', 'NN']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = ['ADJ', 'V', 'NN']\n",
    "\n",
    "corpusCSV = collection.FilterPOS(doclist_csv, pos_tags)\n",
    "corpusCSV.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ParagraphId', 'TokenId', 'Lemma', 'CPOS', 'NamedEntity']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusCSV.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doyle_AStudyinScarlet.txt.csv',\n",
       " 'Doyle_TheHoundoftheBaskervilles.txt.csv',\n",
       " 'Doyle_TheSignoftheFour.txt.csv',\n",
       " 'Howard_GodsoftheNorth.txt.csv',\n",
       " 'Howard_SchadowsinZamboula.txt.csv',\n",
       " 'Howard_ShadowsintheMoonlight.txt.csv',\n",
       " 'Howard_TheDevilinIron.txt.csv',\n",
       " 'Kipling_TheEndofthePassage.txt.csv',\n",
       " 'Kipling_TheJungleBook.txt.csv',\n",
       " 'Kipling_ThyServantaDog.txt.csv',\n",
       " 'Lovecraft_AttheMountainofMadness.txt.csv',\n",
       " 'Lovecraft_TheShunnedHouse.txt.csv',\n",
       " 'Poe_EurekaAProsePoem.txt.csv',\n",
       " 'Poe_TheCaskofAmontillado.txt.csv',\n",
       " 'Poe_TheMasqueoftheRedDeath.txt.csv',\n",
       " 'Poe_ThePurloinedLetter.txt.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = corpusCSV.get_labels()\n",
    "list(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37       typographical\n",
       "56             textual\n",
       "59              square\n",
       "72                 old\n",
       "75                such\n",
       "80             present\n",
       "112           original\n",
       "122           original\n",
       "139              ascii\n",
       "147            latin-1\n",
       "154            present\n",
       "161             french\n",
       "163            spanish\n",
       "169             proper\n",
       "294             second\n",
       "320               deep\n",
       "334              other\n",
       "340               same\n",
       "365                new\n",
       "406              fatal\n",
       "430         subclavian\n",
       "442          murderous\n",
       "458            orderly\n",
       "475            british\n",
       "483               weak\n",
       "486          prolonged\n",
       "499              great\n",
       "525               able\n",
       "537             little\n",
       "548            enteric\n",
       "             ...      \n",
       "50767     irresistible\n",
       "50813           sudden\n",
       "50817           likely\n",
       "50833            least\n",
       "50870         original\n",
       "50878             arab\n",
       "50879        detective\n",
       "50918            fresh\n",
       "50933       unexpected\n",
       "50973            whole\n",
       "50979          logical\n",
       "50991        wonderful\n",
       "51095      sensational\n",
       "51099           sudden\n",
       "51139             good\n",
       "51149              old\n",
       "51152         romantic\n",
       "51174          younger\n",
       "51203            other\n",
       "51209            least\n",
       "51216         striking\n",
       "51222        detective\n",
       "51254          british\n",
       "51260             open\n",
       "51267            smart\n",
       "51296          certain\n",
       "51314        detective\n",
       "51355          fitting\n",
       "51453            simul\n",
       "51454               ac\n",
       "Name: Lemma, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = corpusCSV.get_lemma()\n",
    "list(lemma)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17-Oct-2016 17:43:56 INFO collection: Accessing corpus ...\n",
      "17-Oct-2016 17:43:56 INFO gensim.corpora.indexedcorpus: loaded corpus index from out_off/corpus_off.mm.index\n",
      "17-Oct-2016 17:43:56 INFO gensim.matutils: initializing corpus reader from out_off/corpus_off.mm\n",
      "17-Oct-2016 17:43:56 INFO gensim.matutils: accepted corpus with 6 documents, 1950 features, 1839 non-zero entries\n",
      "17-Oct-2016 17:43:56 INFO collection: Accessing model ...\n",
      "17-Oct-2016 17:43:56 INFO gensim.utils: loading LdaModel object from out_off/corpus_off.lda\n",
      "17-Oct-2016 17:43:56 INFO gensim.utils: loading id2word recursively from out_off/corpus_off.lda.id2word.* with mmap=None\n",
      "17-Oct-2016 17:43:56 INFO gensim.utils: setting ignored attribute dispatcher to None\n",
      "17-Oct-2016 17:43:56 INFO gensim.utils: setting ignored attribute state to None\n",
      "17-Oct-2016 17:43:56 INFO gensim.utils: loading LdaModel object from out_off/corpus_off.lda.state\n",
      "17-Oct-2016 17:43:56 INFO collection: Accessing doc_labels ...\n",
      "17-Oct-2016 17:43:57 INFO collection: Successfully created corpus, model, doc_labels for heatmap visualization.\n"
     ]
    }
   ],
   "source": [
    "# Ingest Gensim stuff\n",
    "\n",
    "lda_model = 'out_off/corpus_off.lda'\n",
    "corpus = 'out_off/corpus_off.mm'\n",
    "dictionary = 'out_off/corpus_off.dict'\n",
    "doc_labels = 'out_off/corpus_off_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17-Oct-2016 17:47:55 INFO collection: Loading topic distribution from model ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LdaModel' object has no attribute 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bb7847f2cee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# eigentlich ganz offensichtlich ist...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/severin/git/Topics/collection.py\u001b[0m in \u001b[0;36mmake_heatmap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading topic distribution from model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_of_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving topic probability ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"\"\"\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dispatcher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# Initialize the variational distribution q(theta|gamma) for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mexpElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LdaModel' object has no attribute 'random_state'"
     ]
    }
   ],
   "source": [
    "# Ich habe das Gef√ºhl, dass der Fehler \n",
    "# eigentlich ganz offensichtlich ist...\n",
    "\n",
    "vis.make_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
