{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `collection.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collection\n",
    "# Warning is Gensim related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_txt = \"corpus_txt\"\n",
    "path_csv = \"corpus_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_txt\\\\Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt\\\\Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt\\\\Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt\\\\Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt\\\\Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_txt = collection.create_document_list(path_txt)\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_csv\\\\Doyle_AStudyinScarlet.txt.csv',\n",
       " 'corpus_csv\\\\Doyle_TheHoundoftheBaskervilles.txt.csv',\n",
       " 'corpus_csv\\\\Doyle_TheSignoftheFour.txt.csv',\n",
       " 'corpus_csv\\\\Howard_GodsoftheNorth.txt.csv',\n",
       " 'corpus_csv\\\\Howard_SchadowsinZamboula.txt.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_csv = collection.create_document_list(path_csv, 'csv')\n",
    "doclist_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_txt = collection.read_from_txt(doclist_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_csv = collection.read_from_csv(doclist_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A SCANDAL IN BOHEMIA\\n\\nA. CONAN DOYLE\\n\\n\\nI\\n\\nTo Sherlock Holmes she is always _the_ woman. I have seldom heard him\\nmention her under any other name. In his eyes she eclipses and\\npredominates the whole of her sex. It was not that he felt any emotion\\nakin to love for Irene Adler. All emotions, and that one particularly,\\nwere abhorrent to his cold, precise but admirably balanced mind. He was,\\nI take it, the most perfect reasoning and observing machine that the\\nworld has seen; but as a lover, he would have placed himself in a false\\nposition. He never spoke of the softer passions, save with a gibe and a\\nsneer. They were admirable things for the observer--excellent for\\ndrawing the veil from men's motives and actions. But for the trained\\nreasoner to admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a distracting factor which might\\nthrow a doubt upon all his mental results. Grit in a sensitive\\ninstrument, or a crack in one of his own high-power lenses, w\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = collection.segmenter(corpus_txt, 1000)\n",
    "next(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counter erstellen um removeStopwords und removeHapax zu verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for doc in corpus_txt:\n",
    "    #split() immer noch, da kein Tokenizer vorhanden und nur temporär zum Testen\n",
    "    counter.update(doc.split())\n",
    "    \n",
    "#\n",
    "# Grenzbote als Counter ca. 100MB groß\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Kopie des ursprünglichen Counters um im Testvorgang den Counter zurückzusetzen\n",
    "# Auf diese Weise muss der Counter nicht jedes Mal erneut erstellt werden,\n",
    "# sondern kann hier zurückgesetzt werden\n",
    "#\n",
    "\n",
    "countercopy = counter.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_without_stopwords = collection.removeStopwords(countercopy, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge des counters:  43989\n",
      "Länge des dicts nachdem Stopwords entfernt wurden:  43969\n",
      "25 MFWs von counter:\n",
      " [('the', 21357), ('of', 11614), ('and', 11040), ('to', 8516), ('a', 7652), ('in', 5585), ('I', 5393), ('that', 4479), ('was', 4211), ('he', 3610), ('his', 3503), ('had', 2816), ('is', 2768), ('with', 2767), ('as', 2733), ('it', 2457), ('for', 2282), ('at', 2272), ('have', 2171), ('which', 2063), ('we', 1963), ('you', 1905), ('not', 1902), ('my', 1833), ('be', 1738)] \n",
      "\n",
      "25 MFWs nachdem stopwords entfernt wurden:\n",
      " [('we', 1963), ('you', 1905), ('not', 1902), ('my', 1833), ('be', 1738), ('on', 1729), ('from', 1670), ('but', 1462), ('were', 1449), ('The', 1424), ('all', 1400), ('by', 1351), ('this', 1284), ('said', 1251), ('He', 1250), ('him', 1082), ('or', 1068), ('an', 1053), ('are', 1042), ('been', 1037), ('our', 1018), ('one', 1018), ('no', 1006), ('me', 978), ('upon', 957)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Länge des counters: \", len(counter))\n",
    "print(\"Länge des dicts nachdem Stopwords entfernt wurden: \", len(dict_without_stopwords))\n",
    "print(\"25 MFWs von counter:\\n\", counter.most_common(25), \"\\n\")\n",
    "print(\"25 MFWs nachdem stopwords entfernt wurden:\\n\", dict_without_stopwords.most_common(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Hapax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_without_hapax = collection.removeHapax(countercopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge des counters:  43989\n",
      "Länge des dicts nachdem Hapax entfernt wurden:  17893\n",
      "Anzahl der Wörter, die öfter als ein Mal vorkommen:  17893\n",
      "Anzahl der Wörter, die genau ein Mal vorkommen:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Länge des counters: \", len(counter))\n",
    "print(\"Länge des dicts nachdem Hapax entfernt wurden: \",len(dict_without_hapax))\n",
    "\n",
    "print(\"Anzahl der Wörter, die öfter als ein Mal vorkommen: \", len([count for count in dict_without_hapax.values() if count > 1]))\n",
    "print(\"Anzahl der Wörter, die genau ein Mal vorkommen: \",len([count for count in dict_without_hapax.values() if count == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmas anhand POS-Tags auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:26 INFO collection: Accessing ['ADJ', 'V', 'NN'] lemmas ...\n",
      "31-Oct-2016 15:19:26 INFO collection: Accessing CSV documents ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37       typographical\n",
       "56             textual\n",
       "59              square\n",
       "72                 old\n",
       "75                such\n",
       "80             present\n",
       "112           original\n",
       "122           original\n",
       "139              ascii\n",
       "147            latin-1\n",
       "154            present\n",
       "161             french\n",
       "163            spanish\n",
       "169             proper\n",
       "294             second\n",
       "320               deep\n",
       "334              other\n",
       "340               same\n",
       "365                new\n",
       "406              fatal\n",
       "430         subclavian\n",
       "442          murderous\n",
       "458            orderly\n",
       "475            british\n",
       "483               weak\n",
       "486          prolonged\n",
       "499              great\n",
       "525               able\n",
       "537             little\n",
       "548            enteric\n",
       "             ...      \n",
       "50767     irresistible\n",
       "50813           sudden\n",
       "50817           likely\n",
       "50833            least\n",
       "50870         original\n",
       "50878             arab\n",
       "50879        detective\n",
       "50918            fresh\n",
       "50933       unexpected\n",
       "50973            whole\n",
       "50979          logical\n",
       "50991        wonderful\n",
       "51095      sensational\n",
       "51099           sudden\n",
       "51139             good\n",
       "51149              old\n",
       "51152         romantic\n",
       "51174          younger\n",
       "51203            other\n",
       "51209            least\n",
       "51216         striking\n",
       "51222        detective\n",
       "51254          british\n",
       "51260             open\n",
       "51267            smart\n",
       "51296          certain\n",
       "51314        detective\n",
       "51355          fitting\n",
       "51453            simul\n",
       "51454               ac\n",
       "Name: Lemma, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = collection.filter_POS_tags(corpus_csv)\n",
    "next(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:26 INFO collection: Creating document labels ...\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Document labels available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Doyle_AScandalinBohemia.txt',\n",
       " 'Doyle_AStudyinScarlet.txt',\n",
       " 'Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'Doyle_TheSignoftheFour.txt',\n",
       " 'Howard_GodsoftheNorth.txt',\n",
       " 'Howard_SchadowsinZamboula.txt',\n",
       " 'Howard_ShadowsintheMoonlight.txt',\n",
       " 'Howard_TheDevilinIron.txt',\n",
       " 'Kipling_TheEndofthePassage.txt',\n",
       " 'Kipling_TheJungleBook.txt',\n",
       " 'Kipling_ThyServantaDog.txt',\n",
       " 'Lovecraft_AttheMountainofMadness.txt',\n",
       " 'Lovecraft_TheShunnedHouse.txt',\n",
       " 'Poe_EurekaAProsePoem.txt',\n",
       " 'Poe_TheCaskofAmontillado.txt',\n",
       " 'Poe_TheMasqueoftheRedDeath.txt',\n",
       " 'Poe_ThePurloinedLetter.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = collection.get_labels(doclist_txt)\n",
    "list(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:26 INFO collection: Accessing corpus ...\n",
      "31-Oct-2016 15:19:26 INFO gensim.corpora.indexedcorpus: loaded corpus index from out_easy/corpus.mm.index\n",
      "31-Oct-2016 15:19:26 INFO gensim.matutils: initializing corpus reader from out_easy/corpus.mm\n",
      "31-Oct-2016 15:19:26 INFO gensim.matutils: accepted corpus with 17 documents, 514 features, 4585 non-zero entries\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Corpus available.\n",
      "31-Oct-2016 15:19:26 INFO collection: Accessing model ...\n",
      "31-Oct-2016 15:19:26 INFO gensim.utils: loading LdaModel object from out_easy/corpus.lda\n",
      "31-Oct-2016 15:19:26 INFO gensim.utils: loading id2word recursively from out_easy/corpus.lda.id2word.* with mmap=None\n",
      "31-Oct-2016 15:19:26 INFO gensim.utils: setting ignored attribute state to None\n",
      "31-Oct-2016 15:19:26 INFO gensim.utils: setting ignored attribute dispatcher to None\n",
      "31-Oct-2016 15:19:26 INFO gensim.utils: loading LdaModel object from out_easy/corpus.lda.state\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Model available.\n",
      "31-Oct-2016 15:19:26 DEBUG collection: :param: interactive == False.\n",
      "31-Oct-2016 15:19:26 INFO collection: Accessing doc_labels ...\n",
      "31-Oct-2016 15:19:26 DEBUG collection: doc_labels accessed.\n",
      "31-Oct-2016 15:19:26 DEBUG collection: 29 doc_labels available.\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Corpus, model and doc_labels available.\n"
     ]
    }
   ],
   "source": [
    "# Da `out_grenzboten` derzeit kaputt ist, wird vorübergehend das\n",
    "# model aus `out_easy` verwendet (stammt aus IntroductionTopics.ipynb)\n",
    "\n",
    "lda_model = 'out_easy/corpus.lda'\n",
    "corpus = 'out_easy/corpus.mm'\n",
    "dictionary = 'out_easy/corpus.dict'\n",
    "doc_labels = 'out_easy/corpus_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:26 INFO collection: Accessing topic distribution ...\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Topic distribution available.\n",
      "31-Oct-2016 15:19:26 INFO collection: Accessing topic probability ...\n",
      "31-Oct-2016 15:19:26 DEBUG collection: Topic probability available.\n",
      "31-Oct-2016 15:19:26 INFO collection: Accessing plot labels ...\n",
      "31-Oct-2016 15:19:26 DEBUG collection: 10 plot labels available.\n",
      "31-Oct-2016 15:19:26 INFO collection: Creating heatmap figure ...\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Heatmap figure available.\n"
     ]
    }
   ],
   "source": [
    "heatmap = vis.make_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:27 INFO collection: Saving heatmap figure...\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Heatmap figure available at ./visualizations/heatmap/heatmap.png\n"
     ]
    }
   ],
   "source": [
    "vis.save_heatmap(\"./visualizations/heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:27 INFO collection: Accessing corpus ...\n",
      "31-Oct-2016 15:19:27 INFO gensim.corpora.indexedcorpus: loaded corpus index from out_easy/corpus.mm.index\n",
      "31-Oct-2016 15:19:27 INFO gensim.matutils: initializing corpus reader from out_easy/corpus.mm\n",
      "31-Oct-2016 15:19:27 INFO gensim.matutils: accepted corpus with 17 documents, 514 features, 4585 non-zero entries\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Corpus available.\n",
      "31-Oct-2016 15:19:27 INFO collection: Accessing model ...\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: loading LdaModel object from out_easy/corpus.lda\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: loading id2word recursively from out_easy/corpus.lda.id2word.* with mmap=None\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: setting ignored attribute state to None\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: setting ignored attribute dispatcher to None\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: loading LdaModel object from out_easy/corpus.lda.state\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Model available.\n",
      "31-Oct-2016 15:19:27 DEBUG collection: :param: interactive == True.\n",
      "31-Oct-2016 15:19:27 INFO collection: Accessing dictionary ...\n",
      "31-Oct-2016 15:19:27 INFO gensim.utils: loading Dictionary object from out_easy/corpus.dict\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Dictionary available.\n",
      "31-Oct-2016 15:19:27 DEBUG collection: Corpus, model and dictionary available.\n"
     ]
    }
   ],
   "source": [
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:27 INFO collection: Accessing model, corpus and dictionary ...\n",
      "31-Oct-2016 15:19:27 DEBUG gensim.models.ldamodel: performing inference on a chunk of 17 documents\n",
      "31-Oct-2016 15:19:27 DEBUG gensim.models.ldamodel: 6/17 documents converged within 50 iterations\n",
      "31-Oct-2016 15:19:28 DEBUG collection: Interactive visualization available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "2      44.980606        1       1  0.004107 -0.022531\n",
       "5      13.908246        1       2  0.037390  0.080774\n",
       "8      10.953661        1       3  0.089735  0.062741\n",
       "9       7.385339        1       4  0.027546  0.065944\n",
       "6       7.324317        1       5 -0.069999  0.046055\n",
       "1       6.010591        1       6 -0.229902  0.005372\n",
       "4       4.780237        1       7  0.032937 -0.138387\n",
       "3       2.421148        1       8  0.003393 -0.009874\n",
       "0       2.231058        1       9  0.079083  0.018599\n",
       "7       0.004798        1      10  0.025711 -0.108691, topic_info=     Category        Freq     Term       Total  loglift  logprob\n",
       "term                                                            \n",
       "474   Default  484.000000   holmes  484.000000  30.0000  30.0000\n",
       "119   Default  986.000000      man  986.000000  29.0000  29.0000\n",
       "38    Default  303.000000    house  303.000000  28.0000  28.0000\n",
       "277   Default  922.000000     will  922.000000  27.0000  27.0000\n",
       "271   Default  562.000000     time  562.000000  26.0000  26.0000\n",
       "86    Default  166.000000   street  166.000000  25.0000  25.0000\n",
       "150   Default  372.000000     head  372.000000  24.0000  24.0000\n",
       "129   Default  269.000000   matter  269.000000  23.0000  23.0000\n",
       "275   Default  459.000000    great  459.000000  22.0000  22.0000\n",
       "161   Default  258.000000     door  258.000000  21.0000  21.0000\n",
       "319   Default  222.000000      don  222.000000  20.0000  20.0000\n",
       "222   Default  209.000000    point  209.000000  19.0000  19.0000\n",
       "95    Default  302.000000     face  302.000000  18.0000  18.0000\n",
       "203   Default  405.000000     eyes  405.000000  17.0000  17.0000\n",
       "420   Default  397.000000    night  397.000000  16.0000  16.0000\n",
       "500   Default  431.000000     long  431.000000  15.0000  15.0000\n",
       "131   Default  337.000000     good  337.000000  14.0000  14.0000\n",
       "331   Default  258.000000   things  258.000000  13.0000  13.0000\n",
       "343   Default  513.000000     well  513.000000  12.0000  12.0000\n",
       "429   Default  253.000000     case  253.000000  11.0000  11.0000\n",
       "402   Default  325.000000     hand  325.000000  10.0000  10.0000\n",
       "147   Default  224.000000   course  224.000000   9.0000   9.0000\n",
       "16    Default  159.000000   watson  159.000000   8.0000   8.0000\n",
       "304   Default  245.000000    thing  245.000000   7.0000   7.0000\n",
       "64    Default  178.000000       ll  178.000000   6.0000   6.0000\n",
       "461   Default  281.000000  thought  281.000000   5.0000   5.0000\n",
       "77    Default  296.000000      day  296.000000   4.0000   4.0000\n",
       "233   Default  250.000000     half  250.000000   3.0000   3.0000\n",
       "32    Default  133.000000     girl  133.000000   2.0000   2.0000\n",
       "261   Default  230.000000     told  230.000000   1.0000   1.0000\n",
       "...       ...         ...      ...         ...      ...      ...\n",
       "420   Topic10    0.007875    night  397.630981  -0.8848  -5.3733\n",
       "150   Topic10    0.007692     head  372.015251  -0.8418  -5.3968\n",
       "491   Topic10    0.005588     walk   99.223519   0.1604  -5.7163\n",
       "277   Topic10    0.008747     will  922.262955  -1.6211  -5.2683\n",
       "131   Topic10    0.006792     good  337.329081  -0.8682  -5.5212\n",
       "500   Topic10    0.007034     long  431.064898  -1.0785  -5.4862\n",
       "77    Topic10    0.006171      day  296.388729  -0.8348  -5.6171\n",
       "402   Topic10    0.006193     hand  325.194537  -0.9240  -5.6136\n",
       "54    Topic10    0.005839    small  238.476184  -0.6727  -5.6724\n",
       "331   Topic10    0.005918   things  258.697468  -0.7407  -5.6591\n",
       "461   Topic10    0.005992  thought  281.412539  -0.8124  -5.6466\n",
       "474   Topic10    0.006574   holmes  484.421495  -1.2627  -5.5538\n",
       "261   Topic10    0.005605     told  230.511320  -0.6796  -5.7133\n",
       "354   Topic10    0.005653     knew  246.523437  -0.7382  -5.7048\n",
       "203   Topic10    0.006134     eyes  405.270350  -1.1537  -5.6231\n",
       "38    Topic10    0.005584    house  303.507486  -0.9585  -5.7171\n",
       "78    Topic10    0.005344    three  237.171390  -0.7557  -5.7610\n",
       "143   Topic10    0.005172    hands  195.238602  -0.5939  -5.7937\n",
       "275   Topic10    0.005873    great  459.724968  -1.3233  -5.6667\n",
       "343   Topic10    0.005846     well  513.660732  -1.4388  -5.6713\n",
       "159   Topic10    0.004634    times  102.126685  -0.0557  -5.9035\n",
       "320   Topic10    0.005091    white  221.451946  -0.7356  -5.8094\n",
       "96    Topic10    0.005237    heard  276.184184  -0.9282  -5.7811\n",
       "241   Topic10    0.005069   looked  234.353886  -0.7967  -5.8138\n",
       "86    Topic10    0.004817   street  166.701434  -0.5070  -5.8648\n",
       "10    Topic10    0.005020     life  234.414895  -0.8066  -5.8235\n",
       "88    Topic10    0.005073     left  256.587934  -0.8865  -5.8131\n",
       "452   Topic10    0.004453     lost  102.215327  -0.0965  -5.9434\n",
       "429   Topic10    0.004964     case  253.147702  -0.8948  -5.8348\n",
       "95    Topic10    0.005033     face  302.253167  -1.0583  -5.8210\n",
       "\n",
       "[613 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "470       7  0.884763         _g_\n",
       "247       7  0.786574         _p_\n",
       "246       7  0.786821         _t_\n",
       "248       6  0.443316       _the_\n",
       "248       7  0.443316       _the_\n",
       "36        1  0.174225  absolutely\n",
       "36        2  0.024889  absolutely\n",
       "36        5  0.049778  absolutely\n",
       "36        6  0.672010  absolutely\n",
       "36        7  0.074668  absolutely\n",
       "14        1  0.261188     account\n",
       "14        2  0.104475     account\n",
       "14        4  0.041790     account\n",
       "14        5  0.083580     account\n",
       "14        6  0.417901     account\n",
       "14        7  0.031343     account\n",
       "14        8  0.041790     account\n",
       "14        9  0.010448     account\n",
       "327       1  0.792563     address\n",
       "327       7  0.132094     address\n",
       "327       9  0.052838     address\n",
       "288       1  0.278935    adjusted\n",
       "288       7  0.557870    adjusted\n",
       "421       7  0.926375       adler\n",
       "482       5  0.282588   admirably\n",
       "482       7  0.565175   admirably\n",
       "120       1  0.196924         ago\n",
       "120       2  0.150589         ago\n",
       "120       3  0.092670         ago\n",
       "120       4  0.034751         ago\n",
       "...     ...       ...         ...\n",
       "506       5  0.046502        word\n",
       "506       6  0.252441        word\n",
       "506       7  0.019930        word\n",
       "506       9  0.006643        word\n",
       "295       1  0.446449        work\n",
       "295       2  0.159840        work\n",
       "295       3  0.033070        work\n",
       "295       4  0.082676        work\n",
       "295       5  0.148816        work\n",
       "295       6  0.060629        work\n",
       "295       7  0.022047        work\n",
       "295       8  0.016535        work\n",
       "295       9  0.027559        work\n",
       "303       1  0.286610       years\n",
       "303       2  0.146229       years\n",
       "303       3  0.046793       years\n",
       "303       4  0.040944       years\n",
       "303       5  0.257364       years\n",
       "303       6  0.122833       years\n",
       "303       7  0.017548       years\n",
       "303       8  0.070190       years\n",
       "303       9  0.017548       years\n",
       "46        1  0.448776       young\n",
       "46        2  0.304526       young\n",
       "46        3  0.058768       young\n",
       "46        4  0.080139       young\n",
       "46        5  0.058768       young\n",
       "46        7  0.026713       young\n",
       "46        8  0.016028       young\n",
       "46        9  0.005343       young\n",
       "\n",
       "[1913 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 6, 9, 10, 7, 2, 5, 4, 1, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.make_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31-Oct-2016 15:19:28 INFO collection: Saving interactive visualization ...\n",
      "31-Oct-2016 15:19:28 DEBUG collection: Interactive visualization available at ./visualizations/interactive/corpus_interactive.html and ./visualizations/interactive/corpus_interactive.json\n"
     ]
    }
   ],
   "source": [
    "vis.save_interactive(\"./visualizations/interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![success](http://cdn2.hubspot.net/hub/128506/file-446943132-jpg/images/computer_woman_success.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
