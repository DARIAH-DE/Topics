{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dariah_topics import preprocessing as pre\n",
    "from dariah_topics import visualization as visual\n",
    "from dariah_topics import mallet as mal\n",
    "# Warning is Gensim related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jan-2017 17:17:13 INFO preprocessing: Creating document list from TXT files ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: 17 entries in document list.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_txt/Poe_EurekaAProsePoem.txt',\n",
       " 'corpus_txt/Howard_TheDevilinIron.txt',\n",
       " 'corpus_txt/Lovecraft_TheShunnedHouse.txt',\n",
       " 'corpus_txt/Howard_SchadowsinZamboula.txt',\n",
       " 'corpus_txt/Doyle_AStudyinScarlet.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_txt = \"corpus_txt\"\n",
    "#path_txt = \"grenzbote_plain/*/\"\n",
    "\n",
    "doclist_txt = pre.create_document_list(path_txt)\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jan-2017 17:17:13 INFO preprocessing: Creating document list from CSV files ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: 16 entries in document list.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_csv/Howard_GodsoftheNorth.txt.csv',\n",
       " 'corpus_csv/Poe_EurekaAProsePoem.txt.csv',\n",
       " 'corpus_csv/Poe_TheMasqueoftheRedDeath.txt.csv',\n",
       " 'corpus_csv/Poe_ThePurloinedLetter.txt.csv',\n",
       " 'corpus_csv/Howard_ShadowsintheMoonlight.txt.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_csv = \"corpus_csv\"\n",
    "\n",
    "doclist_csv = pre.create_document_list(path_csv, 'csv')\n",
    "doclist_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Liste mit Dokumentenlabels erzeugen - (Funktion wird durch Thorsten's generischere Funktion ersetzt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jan-2017 17:17:13 INFO preprocessing: Creating document labels ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Document labels available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_txt/Poe_EurekaAProsePoem.txt',\n",
       " 'corpus_txt/Howard_TheDevilinIron.txt',\n",
       " 'corpus_txt/Lovecraft_TheShunnedHouse.txt',\n",
       " 'corpus_txt/Howard_SchadowsinZamboula.txt',\n",
       " 'corpus_txt/Doyle_AStudyinScarlet.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels = list(pre.get_labels(doclist_txt))\n",
    "doc_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_txt = pre.read_from_txt(doclist_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_csv = pre.read_from_csv(doclist_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Poe_EurekaAProsePoem.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Howard_TheDevilinIron.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Lovecraft_TheShunnedHouse.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Howard_SchadowsinZamboula.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Doyle_AStudyinScarlet.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Poe_TheCaskofAmontillado.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Poe_TheMasqueoftheRedDeath.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Howard_GodsoftheNorth.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Kipling_TheEndofthePassage.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Doyle_TheSignoftheFour.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Kipling_TheJungleBook.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Doyle_AScandalinBohemia.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Poe_ThePurloinedLetter.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Lovecraft_AttheMountainofMadness.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Kipling_ThyServantaDog.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Howard_ShadowsintheMoonlight.txt ...\n",
      "20-Jan-2017 17:17:13 DEBUG preprocessing: Accessing TXT document corpus_txt/Doyle_TheHoundoftheBaskervilles.txt ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<generator object tokenize at 0x7fa7180a3258>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tokens = [pre.tokenize(corpus_txt) for doc in corpus_txt]\n",
    "doc_tokens[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Doc-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_types, doc_dict, doc_ids = pre.create_large_TF_matrix(doc_labels, doc_tokens)\n",
    "\n",
    "termdoc_matrix = {v : k for k, v in id_types.items()}\n",
    "\n",
    "id_docs = {v : k for k, v in doc_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "largecounter = pre.create_large_counter(doc_labels, doc_tokens, termdoc_matrix)\n",
    "\n",
    "largecounter = {id_docs[key] : value for key, value in largecounter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(largecounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sparse_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pd.DataFrame(np.zeros((len(sparse_index.get_level_values('token_id')),1), dtype = int), index = sparse_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_index = pre.create_sparse_index(largecounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_df = populate_two(sparse_index, largecounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_index = pre.create_sparse_index(largecounter)\n",
    "\n",
    "sparse_df = pre.populate_two(sparse_index, largecounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Market Matrix Datei anlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_df.to_csv('sparse_drama.mm', sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_df = sparse_df.sortlevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(sparse_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(sparse_df.index.get_level_values(\"doc_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(sparse_df.index.get_level_values(\"token_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(sparse_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speichern der Market Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_docs = max(sparse_df.index.get_level_values(\"doc_id\"))\n",
    "num_types = max(sparse_df.index.get_level_values(\"token_id\"))\n",
    "sum_counts = sum(sparse_df[0])\n",
    "\n",
    "header_string = str(num_docs) + \" \" + str(num_types) + \" \" + str(sum_counts) + \"\\n\"\n",
    "\n",
    "with open(\"gb_plain.mm\", 'a', encoding = \"utf-8\") as f:\n",
    "    f.write(\"%%MatrixMarket matrix coordinate real general\\n\")\n",
    "    #f.write(header_string)\n",
    "    sparse_df.to_csv( f, sep = ' ', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Feature Remove Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword_list = pre.find_stopwords(docterm_matrix, 100)\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hapax = set(docterm_matrix[docterm_matrix == 1].index)\n",
    "#hapax = set(docterm_matrix[(docterm_matrix < 2).all(axis=1)].index)\n",
    "len(hapax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hapax_list = collection.find_hapax(docterm_matrix)\n",
    "len(hapax_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = stopword_list.union(hapax_list)\n",
    "print(feature_list)\n",
    "clean_term_frequency = docterm_matrix.drop(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = stopword_list.union(hapax_list)\n",
    "clean_term_frequency = collection.remove_features(docterm_matrix, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmata anhand POS-Tags auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas = collection.filter_POS_tags(corpus_csv)\n",
    "next(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpusPath = \"gb_plain.mm\"\n",
    "\n",
    "mm = MmCorpus(corpusPath) #import momentan in visual \n",
    "# -> da ich mir noch nicht sicher bin, welche Funktionen in das tm_gensim.py sollen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in case you're only loading the corpus - build dict first\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump( id_types, open( \"gb_plain.dictionary\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_types = pickle.load(open(\"gb_plain.dictionary\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mm = gensim.corpora.MmCorpus(\"gb_all.mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#id_types = pickle.load(open(\"gb_all.dictionary\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LdaModel(corpus=mm, id2word=id_types, num_topics=60, alpha = \"symmetric\", passes = 10) #import momentan in visual \n",
    "# -> da ich mir noch nicht sicher bin, welche Funktionen in das tm_gensim.py sollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_nr_x = model.get_topic_terms(10)\n",
    "\n",
    "[id_types[i[0]] for i in topic_nr_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = model.show_topics(num_topics = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling mit Mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_corpus = \"corpus_txt\"\n",
    "\n",
    "mallet = mal.call_mallet(path_to_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = 'out_easy/corpus.lda'\n",
    "corpus = 'out_easy/corpus.mm'\n",
    "dictionary = 'out_easy/corpus.dict'\n",
    "doc_labels = 'out_easy/corpus_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = visual.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap = visual.make_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visual.save_heatmap(\"./visualizations/heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis.make_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis.save_interactive(\"./visualizations/interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ob ihr wirklich richtig steht, seht ihr, wenn ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "![success](http://cdn2.hubspot.net/hub/128506/file-446943132-jpg/images/computer_woman_success.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
