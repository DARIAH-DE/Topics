{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from dariah_topics import preprocessing as pre\n",
    "from dariah_topics import visualization as visual\n",
    "from dariah_topics import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_txt/Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt/Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt/Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt/Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt/Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_txt = \"corpus_txt\"\n",
    "#path_txt = \"grenzbote_plain/*/\"\n",
    "#path_txt = \"wiki/\"\n",
    "\n",
    "doclist_txt = pre.create_document_list(path_txt)\n",
    "assert doclist_txt, \"No documents found\"\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Liste mit Dokumentenlabels erzeugen - (Funktion wird durch Thorsten's generischere Funktion ersetzt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_txt/Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt/Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt/Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt/Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt/Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels = list(pre.get_labels(doclist_txt))\n",
    "doc_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_txt = pre.read_from_txt(doclist_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_tokens = [list(pre.tokenize(txt)) for txt in list(corpus_txt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_types, doc_ids = pre.create_dictionaries(doc_labels, doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse BOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_bow = pre.create_mm(doc_labels, doc_tokens, id_types, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>16386</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "doc_id token_id   \n",
       "1      16386     1\n",
       "       4099      5\n",
       "       8199      1\n",
       "       8200      1\n",
       "       8203      6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_bow[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Sparse BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre.save_bow_mm(sparse_bow, \"gensim_txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Market Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import MmCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm = MmCorpus(\"gensim_txt.mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2id = {value : key for key, value in doc_ids.items()}\n",
    "type2id = {value : key for key, value in id_types.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type2id = {value : key for key, value in id_types.items()}\n",
    "sparse_bow_collapsed = sparse_bow.groupby(sparse_bow.index.get_level_values('token_id')).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse_bow_hapax = sparse_bow_collapsed.loc[sparse_bow_collapsed[0] == 1]\n",
    "hapax = [type2id[key] for key in sparse_bow_hapax.index.get_level_values('token_id')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(hapax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "basepath = os.path.abspath('.')\n",
    "\n",
    "with open(os.path.join(basepath, \"tutorial_supplementals\", \"stopwords\", \"de.txt\"), 'r', encoding = 'utf-8') as f: \n",
    "    stopword_list = f.read().split('\\n')\n",
    "    \n",
    "stopword_list = set(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hapax_from_remove = pre.find_hapax(sparse_bow, id_types)\n",
    "stopwords_from_remove = pre.find_stopwords(sparse_bow, id_types, mfw=75)\n",
    "\n",
    "#features_to_be_removed = set(hapax_from_remove + stopwords_from_remove)\n",
    "features_to_be_removed = stopwords_from_remove\n",
    "\n",
    "sparse_bow_short = pre.remove_features(sparse_bow, id_types, features_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre.save_bow_mm(sparse_bow_short, \"gensim_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = MmCorpus(\"gensim_txt.mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sparse_bow to list of (doc, tokens) tuples (like doc2bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2bow_list = []\n",
    "\n",
    "for doc in sparse_bow_short.index.groupby(sparse_bow_short.index.get_level_values('doc_id')):\n",
    "    temp = [(token, count) for token, count in zip(sparse_bow_short.loc[doc].index, sparse_bow_short.loc[doc][0])]\n",
    "    doc2bow_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2bow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = LdaModel(corpus=mm, id2word=type2id, num_topics=60, alpha = \"symmetric\", passes = 10) #import momentan in visual \n",
    "# -> da ich mir noch nicht sicher bin, welche Funktionen in das tm_gensim.py sollen\n",
    "model = LdaModel(corpus=mm, id2word=type2id, num_topics=20, passes = 10, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.02298123755002059),\n",
       " (2, 0.048248106412663416),\n",
       " (3, 0.064324704561025722),\n",
       " (4, 0.11123895320432513),\n",
       " (5, 0.011568753540358575),\n",
       " (8, 0.19381305362048271),\n",
       " (9, 0.22431830012268256),\n",
       " (12, 0.053450979744755898),\n",
       " (13, 0.11564328634623434),\n",
       " (14, 0.087210279745447386),\n",
       " (15, 0.039785817761797376),\n",
       " (18, 0.012440687775811555)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_document_topics(doc2bow_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cordial',\n",
       " 'probes',\n",
       " 'fellow-physicians',\n",
       " 'noise',\n",
       " 'pockets',\n",
       " 'vary',\n",
       " 'rules',\n",
       " 'lease',\n",
       " 'well-digested',\n",
       " 'remained']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anzeige der keywords für topic n\n",
    "n = 1\n",
    "topic_nr_x = model.get_topic_terms(n)\n",
    "\n",
    "topicTerms = [type2id[i[0]] for i in topic_nr_x]\n",
    "topicTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"chattering\" + 0.008*\"indifferently\" + 0.007*\"self-evident\" + 0.006*\"hapur\" + 0.005*\"lingua\" + 0.005*\"quantity\" + 0.005*\"brig\" + 0.005*\"proceeds\" + 0.005*\"varied\" + 0.004*\"connection\"'),\n",
       " (1,\n",
       "  '0.001*\"cordial\" + 0.001*\"probes\" + 0.001*\"fellow-physicians\" + 0.001*\"noise\" + 0.001*\"pockets\" + 0.001*\"vary\" + 0.001*\"rules\" + 0.001*\"lease\" + 0.001*\"well-digested\" + 0.001*\"remained\"'),\n",
       " (2,\n",
       "  '0.008*\"fellow-physicians\" + 0.005*\"pockets\" + 0.005*\"rules\" + 0.005*\"paws-up\" + 0.005*\"oozing\" + 0.004*\"jamming\" + 0.004*\"lease\" + 0.004*\"kaa\" + 0.004*\"coal-owner\" + 0.004*\"well-to\"'),\n",
       " (3,\n",
       "  '0.012*\"chattering\" + 0.005*\"wiping\" + 0.004*\"technical\" + 0.004*\"text\" + 0.004*\"lingua\" + 0.004*\"sounds\" + 0.004*\"farming\" + 0.004*\"nicked\" + 0.004*\"dadoes\" + 0.003*\"drunkenness\"'),\n",
       " (4,\n",
       "  '0.008*\"marked\" + 0.005*\"recede\" + 0.005*\"motions\" + 0.005*\"nicked\" + 0.004*\"included\" + 0.004*\"mightily\" + 0.004*\"lethargy\" + 0.004*\"velveteen\" + 0.004*\"slapped\" + 0.004*\"grabbed\"'),\n",
       " (5,\n",
       "  '0.009*\"fellow-physicians\" + 0.004*\"towering\" + 0.004*\"well-to\" + 0.004*\"vary\" + 0.004*\"slinking\" + 0.004*\"telegraphed\" + 0.004*\"feud\" + 0.004*\"asgard\" + 0.003*\"wood-path\" + 0.003*\"required\"'),\n",
       " (6,\n",
       "  '0.001*\"prestige\" + 0.001*\"stony\" + 0.001*\"reflective\" + 0.001*\"mexborough\" + 0.001*\"stinking\" + 0.001*\"river-water\" + 0.001*\"methodical\" + 0.001*\"fox-at\" + 0.001*\"hunched\" + 0.001*\"tongue\"'),\n",
       " (7,\n",
       "  '0.000*\"well-digested\" + 0.000*\"regaining\" + 0.000*\"paws-up\" + 0.000*\"dadoes\" + 0.000*\"rules\" + 0.000*\"slapped\" + 0.000*\"grabbed\" + 0.000*\"pockets\" + 0.000*\"patalamon\" + 0.000*\"technical\"'),\n",
       " (8,\n",
       "  '0.004*\"alarms\" + 0.004*\"regaining\" + 0.004*\"patalamon\" + 0.004*\"dadoes\" + 0.004*\"spiking\" + 0.004*\"pondicherry\" + 0.003*\"alive\" + 0.003*\"technical\" + 0.003*\"invited\" + 0.003*\"ether’s\"'),\n",
       " (9,\n",
       "  '0.008*\"cordial\" + 0.005*\"well-digested\" + 0.005*\"meek\" + 0.004*\"ever-memorable\" + 0.004*\"feud\" + 0.004*\"telegraphed\" + 0.004*\"grabbed\" + 0.004*\"unattainable\" + 0.004*\"fellow-physicians\" + 0.004*\"towering\"'),\n",
       " (10,\n",
       "  '0.002*\"collected\" + 0.001*\"chattering\" + 0.001*\"lisping\" + 0.001*\"unslinging\" + 0.001*\"shuts\" + 0.001*\"will\" + 0.001*\"meaning\" + 0.001*\"grossest\" + 0.001*\"giant\\'s\" + 0.001*\"players\"'),\n",
       " (11,\n",
       "  '0.000*\"well-digested\" + 0.000*\"pockets\" + 0.000*\"dadoes\" + 0.000*\"nicked\" + 0.000*\"shorter\" + 0.000*\"rules\" + 0.000*\"wood-path\" + 0.000*\"july\" + 0.000*\"grabbed\" + 0.000*\"ever-memorable\"'),\n",
       " (12,\n",
       "  '0.006*\"stock-undoubtedly\" + 0.006*\"burners\" + 0.004*\"asgard\" + 0.004*\"rovers\" + 0.004*\"invited\" + 0.003*\"pried\" + 0.003*\"grandeurs\" + 0.003*\"omniscience\" + 0.003*\"shorter\" + 0.003*\"included\"'),\n",
       " (13,\n",
       "  '0.005*\"fellow-physicians\" + 0.004*\"shorter\" + 0.004*\"bentham\" + 0.003*\"gesticulation\" + 0.003*\"regaining\" + 0.003*\"grabbed\" + 0.003*\"perished\" + 0.003*\"ware-chicken\" + 0.003*\"ever-memorable\" + 0.003*\"profited\"'),\n",
       " (14,\n",
       "  '0.009*\"dadoes\" + 0.006*\"intents\" + 0.006*\"regaining\" + 0.005*\"crystal\" + 0.005*\"disgraceful\" + 0.005*\"slain\" + 0.004*\"trash-like\" + 0.004*\"well-to\" + 0.004*\"haziness\" + 0.004*\"unless\"'),\n",
       " (15,\n",
       "  '0.007*\"chattering\" + 0.006*\"self-evident\" + 0.006*\"technical\" + 0.004*\"tramped\" + 0.004*\"patalamon\" + 0.004*\"majestic\" + 0.004*\"howdah\" + 0.003*\"well-digested\" + 0.003*\"invited\" + 0.003*\"thwarted\"'),\n",
       " (16,\n",
       "  '0.000*\"technical\" + 0.000*\"well-digested\" + 0.000*\"nicked\" + 0.000*\"bentham\" + 0.000*\"rules\" + 0.000*\"patalamon\" + 0.000*\"invited\" + 0.000*\"regaining\" + 0.000*\"intents\" + 0.000*\"slapped\"'),\n",
       " (17,\n",
       "  '0.005*\"silhouette\" + 0.004*\"technical\" + 0.004*\"offing\" + 0.003*\"intents\" + 0.003*\"dadoes\" + 0.003*\"indelibly\" + 0.003*\"ether’s\" + 0.003*\"unless\" + 0.003*\"opposing\" + 0.003*\"draggled\"'),\n",
       " (18,\n",
       "  '0.008*\"lawlessness\" + 0.007*\"tractable\" + 0.005*\"technical\" + 0.004*\"forgetting\" + 0.004*\"wiping\" + 0.004*\"hybrids\" + 0.004*\"mitra\" + 0.004*\"shorter\" + 0.003*\"crashings\" + 0.003*\"sounds\"'),\n",
       " (19,\n",
       "  '0.007*\"gratifying\" + 0.006*\"heatleigh\" + 0.006*\"hearty\" + 0.004*\"dadoes\" + 0.004*\"trash-like\" + 0.003*\"millennially\" + 0.003*\"intents\" + 0.003*\"beckoned\" + 0.003*\"her-side\" + 0.003*\"dash-wise\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic probabilities\n",
    "topics = model.show_topics(num_topics = 40)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "def gensim2dataframe(model):\n",
    "    num_topics = model.num_topics\n",
    "    topics_df = pd.DataFrame(index = range(num_topics), columns= range(10))\n",
    "\n",
    "    topics = model.show_topics(num_topics)\n",
    "    \n",
    "    for topic_dist in topics:    \n",
    "        idx = topic_dist[0]\n",
    "        temp = re.findall(r'\\\"(.+?)\\\"', topics[idx][1])\n",
    "        topics_df.loc[idx] = temp\n",
    "    \n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_df = gensim2dataframe(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic = topics_df.T\n",
    "doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''lda_model = 'out_easy/corpus.lda'\n",
    "corpus = 'out_easy/corpus.mm'\n",
    "dictionary = 'out_easy/corpus.dict'\n",
    "doc_labels = 'out_easy/corpus_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = visual.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a document-topic matrix (that is a pandas data frame actually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic = visual.create_doc_topic(mm, model, doc_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "visual.doc_topic_heatmap(doc_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize topic distribution in a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visual.plot_doc_topics(doc_topic, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![success](http://cdn2.hubspot.net/hub/128506/file-446943132-jpg/images/computer_woman_success.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
