{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "from dariah_topics import preprocessing as pre\n",
    "from dariah_topics import visualization as visual\n",
    "from dariah_topics import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "c:\\users\\philip\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\IPython\\core\\formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_txt\\\\Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt\\\\Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt\\\\Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt\\\\Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt\\\\Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_txt = \"corpus_txt\"\n",
    "#path_txt = \"grenzbote_plain/*/\"\n",
    "#path_txt = \"wiki/\"\n",
    "\n",
    "doclist_txt = pre.create_document_list(path_txt)\n",
    "assert doclist_txt, \"No documents found\"\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Liste mit Dokumentenlabels erzeugen - (Funktion wird durch Thorsten's generischere Funktion ersetzt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus_txt\\\\Doyle_AScandalinBohemia.txt',\n",
       " 'corpus_txt\\\\Doyle_AStudyinScarlet.txt',\n",
       " 'corpus_txt\\\\Doyle_TheHoundoftheBaskervilles.txt',\n",
       " 'corpus_txt\\\\Doyle_TheSignoftheFour.txt',\n",
       " 'corpus_txt\\\\Howard_GodsoftheNorth.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels = list(pre.get_labels(doclist_txt))\n",
    "doc_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_txt = pre.read_from_txt(doclist_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_tokens = [list(pre.tokenize(txt)) for txt in list(corpus_txt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_types, doc_ids = pre.create_dictionaries(doc_labels, doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse BOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_bow = pre.create_mm(doc_labels, doc_tokens, id_types, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>16387</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12294</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20488</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "doc_id token_id    \n",
       "1      16387      1\n",
       "       20484     11\n",
       "       12294      1\n",
       "       20487      1\n",
       "       20488      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_bow[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Sparse BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre.save_bow_mm(sparse_bow, \"gensim_txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Market Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import MmCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm = MmCorpus(\"gensim_txt.mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2id = {value : key for key, value in doc_ids.items()}\n",
    "type2id = {value : key for key, value in id_types.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type2id = {value : key for key, value in id_types.items()}\n",
    "sparse_bow_collapsed = sparse_bow.groupby(sparse_bow.index.get_level_values('token_id')).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse_bow_hapax = sparse_bow_collapsed.loc[sparse_bow_collapsed[0] == 1]\n",
    "hapax = [type2id[key] for key in sparse_bow_hapax.index.get_level_values('token_id')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(hapax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "basepath = os.path.abspath('.')\n",
    "\n",
    "with open(os.path.join(basepath, \"tutorial_supplementals\", \"stopwords\", \"de.txt\"), 'r', encoding = 'utf-8') as f: \n",
    "    stopword_list = f.read().split('\\n')\n",
    "    \n",
    "stopword_list = set(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hapax_from_remove = pre.find_hapax(sparse_bow, id_types)\n",
    "stopwords_from_remove = pre.find_stopwords(sparse_bow, id_types, mfw=75)\n",
    "\n",
    "#features_to_be_removed = set(hapax_from_remove + stopwords_from_remove)\n",
    "features_to_be_removed = stopwords_from_remove\n",
    "\n",
    "sparse_bow_short = pre.remove_features(sparse_bow, id_types, features_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre.save_bow_mm(sparse_bow_short, \"gensim_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = MmCorpus(\"gensim_txt.mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sparse_bow to list of (doc, tokens) tuples (like doc2bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2bow_list = []\n",
    "\n",
    "for doc in sparse_bow_short.index.groupby(sparse_bow_short.index.get_level_values('doc_id')):\n",
    "    temp = [(token, count) for token, count in zip(sparse_bow_short.loc[doc].index, sparse_bow_short.loc[doc][0])]\n",
    "    doc2bow_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2bow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = LdaModel(corpus=mm, id2word=type2id, num_topics=60, alpha = \"symmetric\", passes = 10) #import momentan in visual \n",
    "# -> da ich mir noch nicht sicher bin, welche Funktionen in das tm_gensim.py sollen\n",
    "model = LdaModel(corpus=mm, id2word=type2id, num_topics=20, passes = 10, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.012883995158465566),\n",
       " (4, 0.19288311761917948),\n",
       " (5, 0.04973348232002954),\n",
       " (6, 0.016222277513200763),\n",
       " (8, 0.02331851033351949),\n",
       " (9, 0.36808773472395012),\n",
       " (12, 0.11374919978057629),\n",
       " (14, 0.11883524242343806),\n",
       " (19, 0.089757021026767886)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_document_topics(doc2bow_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assured',\n",
       " 'gnashing',\n",
       " 'pranks',\n",
       " 'confession',\n",
       " 'pea-shooter',\n",
       " 'sentry',\n",
       " 'new-york',\n",
       " 'termed',\n",
       " 'apples',\n",
       " 'hansom']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anzeige der keywords für topic n\n",
    "n = 1\n",
    "topic_nr_x = model.get_topic_terms(n)\n",
    "\n",
    "topicTerms = [type2id[i[0]] for i in topic_nr_x]\n",
    "topicTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"menace\" + 0.004*\"hornets\" + 0.004*\"littlest\" + 0.003*\"termed\" + 0.003*\"apples\" + 0.003*\"implore\" + 0.003*\"roofless\" + 0.003*\"introspective\" + 0.003*\"coincide\" + 0.003*\"nervous\"'),\n",
       " (1,\n",
       "  '0.000*\"assured\" + 0.000*\"gnashing\" + 0.000*\"pranks\" + 0.000*\"confession\" + 0.000*\"pea-shooter\" + 0.000*\"sentry\" + 0.000*\"new-york\" + 0.000*\"termed\" + 0.000*\"apples\" + 0.000*\"hansom\"'),\n",
       " (2,\n",
       "  '0.001*\"inaction\" + 0.001*\"new-york\" + 0.000*\"confession\" + 0.000*\"lanky\" + 0.000*\"assured\" + 0.000*\"pea-shooter\" + 0.000*\"sentry\" + 0.000*\"cabdriver\" + 0.000*\"local\" + 0.000*\"termed\"'),\n",
       " (3,\n",
       "  '0.000*\"assured\" + 0.000*\"collected\" + 0.000*\"confession\" + 0.000*\"pea-shooter\" + 0.000*\"bitten\" + 0.000*\"sentry\" + 0.000*\"stone-cast\" + 0.000*\"gulfs\" + 0.000*\"new-york\" + 0.000*\"with\"'),\n",
       " (4,\n",
       "  '0.004*\"gnashing\" + 0.004*\"hornets\" + 0.003*\"sentry\" + 0.003*\"stone-cast\" + 0.003*\"local\" + 0.003*\"assured\" + 0.003*\"separateness\" + 0.003*\"excesses\" + 0.003*\"with\" + 0.003*\"luminous\"'),\n",
       " (5,\n",
       "  '0.016*\"drop\" + 0.005*\"expressly\" + 0.005*\"serious\" + 0.005*\"hornets\" + 0.004*\"henrietta\" + 0.004*\"authentically\" + 0.004*\"momentum\" + 0.004*\"pranks\" + 0.004*\"excesses\" + 0.004*\"termed\"'),\n",
       " (6,\n",
       "  '0.007*\"peeling\" + 0.007*\"chuckle\" + 0.006*\"internal\" + 0.006*\"lot\" + 0.005*\"nonchalance\" + 0.005*\"veil\" + 0.003*\"invalid\" + 0.003*\"bruises\" + 0.003*\"perversity\" + 0.003*\"need\"'),\n",
       " (7,\n",
       "  '0.008*\"dumps\" + 0.007*\"linkages\" + 0.005*\"hornets\" + 0.004*\"devil\" + 0.004*\"aesthetic\" + 0.004*\"expressly\" + 0.004*\"objective\" + 0.004*\"gnashing\" + 0.003*\"puffs\" + 0.003*\"henrietta\"'),\n",
       " (8,\n",
       "  '0.011*\"yelped\" + 0.008*\"rolled\" + 0.007*\"splashing\" + 0.006*\"dolphin-jump\" + 0.005*\"terribly\" + 0.005*\"plenty-more\" + 0.005*\"admired\" + 0.005*\"miskatonic\" + 0.003*\"grievances\" + 0.003*\"termed\"'),\n",
       " (9,\n",
       "  '0.005*\"inaction\" + 0.005*\"sentry\" + 0.003*\"confession\" + 0.003*\"assured\" + 0.003*\"collected\" + 0.003*\"momentum\" + 0.003*\"terribly\" + 0.003*\"lanky\" + 0.003*\"bitten\" + 0.003*\"hansom\"'),\n",
       " (10,\n",
       "  '0.000*\"stone-cast\" + 0.000*\"with\" + 0.000*\"pranks\" + 0.000*\"flagged\" + 0.000*\"terribly\" + 0.000*\"stockwell\" + 0.000*\"luminous\" + 0.000*\"converses\" + 0.000*\"verdure\" + 0.000*\"scour\"'),\n",
       " (11,\n",
       "  '0.001*\"expanded\" + 0.001*\"flicker\" + 0.001*\"with\" + 0.001*\"virtues\" + 0.001*\"leaves-was\" + 0.001*\"garment\" + 0.001*\"hoisted\" + 0.001*\"solitude\" + 0.001*\"handsomely\" + 0.001*\"glassy-eyed\"'),\n",
       " (12,\n",
       "  '0.007*\"gorgeous\" + 0.005*\"detective\\'s\" + 0.005*\"temptation\" + 0.005*\"pranks\" + 0.004*\"stockwell\" + 0.004*\"preoccupations\" + 0.004*\"bits\" + 0.004*\"jutted\" + 0.004*\"enabling\" + 0.004*\"luminous\"'),\n",
       " (13,\n",
       "  '0.000*\"terribly\" + 0.000*\"confession\" + 0.000*\"luminous\" + 0.000*\"new-york\" + 0.000*\"with\" + 0.000*\"local\" + 0.000*\"termed\" + 0.000*\"stone-cast\" + 0.000*\"assured\" + 0.000*\"momentum\"'),\n",
       " (14,\n",
       "  '0.010*\"virtues\" + 0.007*\"paws\" + 0.006*\"imagining\" + 0.006*\"with\" + 0.005*\"momentum\" + 0.005*\"segwegated\" + 0.005*\"larder\" + 0.005*\"decorously\" + 0.005*\"converses\" + 0.004*\"knots\"'),\n",
       " (15,\n",
       "  '0.000*\"momentum\" + 0.000*\"stone-cast\" + 0.000*\"terribly\" + 0.000*\"local\" + 0.000*\"hornets\" + 0.000*\"with\" + 0.000*\"new-york\" + 0.000*\"converses\" + 0.000*\"bitten\" + 0.000*\"separateness\"'),\n",
       " (16,\n",
       "  '0.001*\"termed\" + 0.001*\"framing\" + 0.001*\"feels\" + 0.001*\"five-tenths\" + 0.001*\"terribly\" + 0.001*\"apples\" + 0.000*\"utterly\" + 0.000*\"local\" + 0.000*\"assured\" + 0.000*\"collected\"'),\n",
       " (17,\n",
       "  '0.001*\"bedsyou-two\" + 0.001*\"profundity\" + 0.001*\"ouach\" + 0.001*\"freshness\" + 0.001*\"sssss\" + 0.001*\"count\" + 0.001*\"bicknell\" + 0.001*\"lukewarmness\" + 0.001*\"discreet\" + 0.001*\"omissions\"'),\n",
       " (18,\n",
       "  '0.001*\"gorgeous\" + 0.001*\"stone-cast\" + 0.001*\"beast-like\" + 0.001*\"brothers\" + 0.001*\"missus\" + 0.001*\"leopard\" + 0.001*\"fatuity\" + 0.001*\"plaza\" + 0.001*\"porous\" + 0.001*\"precept\"'),\n",
       " (19,\n",
       "  '0.009*\"termed\" + 0.006*\"apples\" + 0.006*\"assured\" + 0.005*\"utterly\" + 0.005*\"wrist\" + 0.005*\"jaunty\" + 0.004*\"monotonous\" + 0.004*\"cabdriver\" + 0.004*\"packing\" + 0.004*\"roofless\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic probabilities\n",
    "topics = model.show_topics(num_topics = 40)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "def gensim2dataframe(model):\n",
    "    num_topics = model.num_topics\n",
    "    topics_df = pd.DataFrame(index = range(num_topics), columns= range(10))\n",
    "\n",
    "    topics = model.show_topics(num_topics)\n",
    "    \n",
    "    for topic_dist in topics:    \n",
    "        idx = topic_dist[0]\n",
    "        temp = re.findall(r'\\\"(.+?)\\\"', topics[idx][1])\n",
    "        topics_df.loc[idx] = temp\n",
    "    \n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_df = gensim2dataframe(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>menace</td>\n",
       "      <td>hornets</td>\n",
       "      <td>littlest</td>\n",
       "      <td>termed</td>\n",
       "      <td>apples</td>\n",
       "      <td>implore</td>\n",
       "      <td>roofless</td>\n",
       "      <td>introspective</td>\n",
       "      <td>coincide</td>\n",
       "      <td>nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assured</td>\n",
       "      <td>gnashing</td>\n",
       "      <td>pranks</td>\n",
       "      <td>confession</td>\n",
       "      <td>pea-shooter</td>\n",
       "      <td>sentry</td>\n",
       "      <td>new-york</td>\n",
       "      <td>termed</td>\n",
       "      <td>apples</td>\n",
       "      <td>hansom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inaction</td>\n",
       "      <td>new-york</td>\n",
       "      <td>confession</td>\n",
       "      <td>lanky</td>\n",
       "      <td>assured</td>\n",
       "      <td>pea-shooter</td>\n",
       "      <td>sentry</td>\n",
       "      <td>cabdriver</td>\n",
       "      <td>local</td>\n",
       "      <td>termed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assured</td>\n",
       "      <td>collected</td>\n",
       "      <td>confession</td>\n",
       "      <td>pea-shooter</td>\n",
       "      <td>bitten</td>\n",
       "      <td>sentry</td>\n",
       "      <td>stone-cast</td>\n",
       "      <td>gulfs</td>\n",
       "      <td>new-york</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gnashing</td>\n",
       "      <td>hornets</td>\n",
       "      <td>sentry</td>\n",
       "      <td>stone-cast</td>\n",
       "      <td>local</td>\n",
       "      <td>assured</td>\n",
       "      <td>separateness</td>\n",
       "      <td>excesses</td>\n",
       "      <td>with</td>\n",
       "      <td>luminous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drop</td>\n",
       "      <td>expressly</td>\n",
       "      <td>serious</td>\n",
       "      <td>hornets</td>\n",
       "      <td>henrietta</td>\n",
       "      <td>authentically</td>\n",
       "      <td>momentum</td>\n",
       "      <td>pranks</td>\n",
       "      <td>excesses</td>\n",
       "      <td>termed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peeling</td>\n",
       "      <td>chuckle</td>\n",
       "      <td>internal</td>\n",
       "      <td>lot</td>\n",
       "      <td>nonchalance</td>\n",
       "      <td>veil</td>\n",
       "      <td>invalid</td>\n",
       "      <td>bruises</td>\n",
       "      <td>perversity</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dumps</td>\n",
       "      <td>linkages</td>\n",
       "      <td>hornets</td>\n",
       "      <td>devil</td>\n",
       "      <td>aesthetic</td>\n",
       "      <td>expressly</td>\n",
       "      <td>objective</td>\n",
       "      <td>gnashing</td>\n",
       "      <td>puffs</td>\n",
       "      <td>henrietta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yelped</td>\n",
       "      <td>rolled</td>\n",
       "      <td>splashing</td>\n",
       "      <td>dolphin-jump</td>\n",
       "      <td>terribly</td>\n",
       "      <td>plenty-more</td>\n",
       "      <td>admired</td>\n",
       "      <td>miskatonic</td>\n",
       "      <td>grievances</td>\n",
       "      <td>termed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inaction</td>\n",
       "      <td>sentry</td>\n",
       "      <td>confession</td>\n",
       "      <td>assured</td>\n",
       "      <td>collected</td>\n",
       "      <td>momentum</td>\n",
       "      <td>terribly</td>\n",
       "      <td>lanky</td>\n",
       "      <td>bitten</td>\n",
       "      <td>hansom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stone-cast</td>\n",
       "      <td>with</td>\n",
       "      <td>pranks</td>\n",
       "      <td>flagged</td>\n",
       "      <td>terribly</td>\n",
       "      <td>stockwell</td>\n",
       "      <td>luminous</td>\n",
       "      <td>converses</td>\n",
       "      <td>verdure</td>\n",
       "      <td>scour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>expanded</td>\n",
       "      <td>flicker</td>\n",
       "      <td>with</td>\n",
       "      <td>virtues</td>\n",
       "      <td>leaves-was</td>\n",
       "      <td>garment</td>\n",
       "      <td>hoisted</td>\n",
       "      <td>solitude</td>\n",
       "      <td>handsomely</td>\n",
       "      <td>glassy-eyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gorgeous</td>\n",
       "      <td>detective's</td>\n",
       "      <td>temptation</td>\n",
       "      <td>pranks</td>\n",
       "      <td>stockwell</td>\n",
       "      <td>preoccupations</td>\n",
       "      <td>bits</td>\n",
       "      <td>jutted</td>\n",
       "      <td>enabling</td>\n",
       "      <td>luminous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>terribly</td>\n",
       "      <td>confession</td>\n",
       "      <td>luminous</td>\n",
       "      <td>new-york</td>\n",
       "      <td>with</td>\n",
       "      <td>local</td>\n",
       "      <td>termed</td>\n",
       "      <td>stone-cast</td>\n",
       "      <td>assured</td>\n",
       "      <td>momentum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>virtues</td>\n",
       "      <td>paws</td>\n",
       "      <td>imagining</td>\n",
       "      <td>with</td>\n",
       "      <td>momentum</td>\n",
       "      <td>segwegated</td>\n",
       "      <td>larder</td>\n",
       "      <td>decorously</td>\n",
       "      <td>converses</td>\n",
       "      <td>knots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>momentum</td>\n",
       "      <td>stone-cast</td>\n",
       "      <td>terribly</td>\n",
       "      <td>local</td>\n",
       "      <td>hornets</td>\n",
       "      <td>with</td>\n",
       "      <td>new-york</td>\n",
       "      <td>converses</td>\n",
       "      <td>bitten</td>\n",
       "      <td>separateness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>termed</td>\n",
       "      <td>framing</td>\n",
       "      <td>feels</td>\n",
       "      <td>five-tenths</td>\n",
       "      <td>terribly</td>\n",
       "      <td>apples</td>\n",
       "      <td>utterly</td>\n",
       "      <td>local</td>\n",
       "      <td>assured</td>\n",
       "      <td>collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bedsyou-two</td>\n",
       "      <td>profundity</td>\n",
       "      <td>ouach</td>\n",
       "      <td>freshness</td>\n",
       "      <td>sssss</td>\n",
       "      <td>count</td>\n",
       "      <td>bicknell</td>\n",
       "      <td>lukewarmness</td>\n",
       "      <td>discreet</td>\n",
       "      <td>omissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gorgeous</td>\n",
       "      <td>stone-cast</td>\n",
       "      <td>beast-like</td>\n",
       "      <td>brothers</td>\n",
       "      <td>missus</td>\n",
       "      <td>leopard</td>\n",
       "      <td>fatuity</td>\n",
       "      <td>plaza</td>\n",
       "      <td>porous</td>\n",
       "      <td>precept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>termed</td>\n",
       "      <td>apples</td>\n",
       "      <td>assured</td>\n",
       "      <td>utterly</td>\n",
       "      <td>wrist</td>\n",
       "      <td>jaunty</td>\n",
       "      <td>monotonous</td>\n",
       "      <td>cabdriver</td>\n",
       "      <td>packing</td>\n",
       "      <td>roofless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1           2             3            4  \\\n",
       "0        menace      hornets    littlest        termed       apples   \n",
       "1       assured     gnashing      pranks    confession  pea-shooter   \n",
       "2      inaction     new-york  confession         lanky      assured   \n",
       "3       assured    collected  confession   pea-shooter       bitten   \n",
       "4      gnashing      hornets      sentry    stone-cast        local   \n",
       "5          drop    expressly     serious       hornets    henrietta   \n",
       "6       peeling      chuckle    internal           lot  nonchalance   \n",
       "7         dumps     linkages     hornets         devil    aesthetic   \n",
       "8        yelped       rolled   splashing  dolphin-jump     terribly   \n",
       "9      inaction       sentry  confession       assured    collected   \n",
       "10   stone-cast         with      pranks       flagged     terribly   \n",
       "11     expanded      flicker        with       virtues   leaves-was   \n",
       "12     gorgeous  detective's  temptation        pranks    stockwell   \n",
       "13     terribly   confession    luminous      new-york         with   \n",
       "14      virtues         paws   imagining          with     momentum   \n",
       "15     momentum   stone-cast    terribly         local      hornets   \n",
       "16       termed      framing       feels   five-tenths     terribly   \n",
       "17  bedsyou-two   profundity       ouach     freshness        sssss   \n",
       "18     gorgeous   stone-cast  beast-like      brothers       missus   \n",
       "19       termed       apples     assured       utterly        wrist   \n",
       "\n",
       "                 5             6              7           8             9  \n",
       "0          implore      roofless  introspective    coincide       nervous  \n",
       "1           sentry      new-york         termed      apples        hansom  \n",
       "2      pea-shooter        sentry      cabdriver       local        termed  \n",
       "3           sentry    stone-cast          gulfs    new-york          with  \n",
       "4          assured  separateness       excesses        with      luminous  \n",
       "5    authentically      momentum         pranks    excesses        termed  \n",
       "6             veil       invalid        bruises  perversity          need  \n",
       "7        expressly     objective       gnashing       puffs     henrietta  \n",
       "8      plenty-more       admired     miskatonic  grievances        termed  \n",
       "9         momentum      terribly          lanky      bitten        hansom  \n",
       "10       stockwell      luminous      converses     verdure         scour  \n",
       "11         garment       hoisted       solitude  handsomely   glassy-eyed  \n",
       "12  preoccupations          bits         jutted    enabling      luminous  \n",
       "13           local        termed     stone-cast     assured      momentum  \n",
       "14      segwegated        larder     decorously   converses         knots  \n",
       "15            with      new-york      converses      bitten  separateness  \n",
       "16          apples       utterly          local     assured     collected  \n",
       "17           count      bicknell   lukewarmness    discreet     omissions  \n",
       "18         leopard       fatuity          plaza      porous       precept  \n",
       "19          jaunty    monotonous      cabdriver     packing      roofless  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''lda_model = 'out_easy/corpus.lda'\n",
    "corpus = 'out_easy/corpus.mm'\n",
    "dictionary = 'out_easy/corpus.dict'\n",
    "doc_labels = 'out_easy/corpus_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = visual.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a document-topic matrix (that is a pandas data frame actually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic = visual.create_doc_topic(mm, model, doc_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "visual.doc_topic_heatmap(doc_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize topic distribution in a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visual.plot_doc_topics(doc_topic, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![success](http://cdn2.hubspot.net/hub/128506/file-446943132-jpg/images/computer_woman_success.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
