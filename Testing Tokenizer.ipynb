{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "import collection\n",
    "\n",
    "french = \"U.S.A. Français! «Oui», \\\"m'éveillai\\\" étant \\'Tchouang-tseu\\'... Suis-je réalité? Qui rêve qu'il qui s'imagine!\"\n",
    "spanish = \"U.S.A. Español! «Sí», \\\"de programación\\\" y años después del sueño léxico... \\'Matemático meta-aplicado\\'?\"\n",
    "english = \"U.S.A. English! «Yes», it's \\\"the\\\" leaf-cutting ant at five o'clock... \\'Didn't I say?\\'\"\n",
    "portuguese = \"U.S.A. Português! «Sim», \\\"ciência\\\" da computação é a ciência que estuda as técnicas... \\'Classifica-se\\' como ciência?\"\n",
    "german = \"U.S.A. Deutsch! «Ja», wie geht's? \\\"Ein typisches Beispiel\\\" für ein System... OK, \\'verbundenes-wort\\'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:46 INFO collection: Tokenizing with \\p{Letter}[\\p{Letter}\\p{Punctuation}]*\\p{Letter}|\\p{Letter}{1} ...\n",
      "09-Jan-2017 16:53:46 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'français' was found between the indices (4, 12)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'oui' was found between the indices (15, 18)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'm'éveillai' was found between the indices (22, 32)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'étant' was found between the indices (34, 39)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'tchouang-tseu' was found between the indices (41, 54)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'suis-je' was found between the indices (56, 63)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'réalité' was found between the indices (64, 71)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'qui' was found between the indices (73, 76)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'rêve' was found between the indices (77, 81)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'qu'il' was found between the indices (82, 87)\n",
      "09-Jan-2017 16:53:46 INFO collection: 'qui' was found between the indices (88, 91)\n",
      "09-Jan-2017 16:53:46 INFO collection: 's'imagine' was found between the indices (92, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'français',\n",
       " 'oui',\n",
       " \"m'éveillai\",\n",
       " 'étant',\n",
       " 'tchouang-tseu',\n",
       " 'suis-je',\n",
       " 'réalité',\n",
       " 'qui',\n",
       " 'rêve',\n",
       " \"qu'il\",\n",
       " 'qui',\n",
       " \"s'imagine\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(french))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:48 INFO collection: Tokenizing with \\w+ ...\n",
      "09-Jan-2017 16:53:48 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'français' was found between the indices (4, 12)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'oui' was found between the indices (15, 18)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'm' was found between the indices (22, 23)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'éveillai' was found between the indices (24, 32)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'étant' was found between the indices (34, 39)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'tchouang' was found between the indices (41, 49)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'tseu' was found between the indices (50, 54)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'suis' was found between the indices (56, 60)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'je' was found between the indices (61, 63)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'réalité' was found between the indices (64, 71)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'qui' was found between the indices (73, 76)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'rêve' was found between the indices (77, 81)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'qu' was found between the indices (82, 84)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'il' was found between the indices (85, 87)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'qui' was found between the indices (88, 91)\n",
      "09-Jan-2017 16:53:48 INFO collection: 's' was found between the indices (92, 93)\n",
      "09-Jan-2017 16:53:48 INFO collection: 'imagine' was found between the indices (94, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'français',\n",
       " 'oui',\n",
       " 'm',\n",
       " 'éveillai',\n",
       " 'étant',\n",
       " 'tchouang',\n",
       " 'tseu',\n",
       " 'suis',\n",
       " 'je',\n",
       " 'réalité',\n",
       " 'qui',\n",
       " 'rêve',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'qui',\n",
       " 's',\n",
       " 'imagine']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(french, simple=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:49 INFO collection: Tokenizing with \\p{Letter}+ ...\n",
      "09-Jan-2017 16:53:49 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'français' was found between the indices (4, 12)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'oui' was found between the indices (15, 18)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'm' was found between the indices (22, 23)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'éveillai' was found between the indices (24, 32)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'étant' was found between the indices (34, 39)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'tchouang' was found between the indices (41, 49)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'tseu' was found between the indices (50, 54)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'suis' was found between the indices (56, 60)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'je' was found between the indices (61, 63)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'réalité' was found between the indices (64, 71)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'qui' was found between the indices (73, 76)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'rêve' was found between the indices (77, 81)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'qu' was found between the indices (82, 84)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'il' was found between the indices (85, 87)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'qui' was found between the indices (88, 91)\n",
      "09-Jan-2017 16:53:49 INFO collection: 's' was found between the indices (92, 93)\n",
      "09-Jan-2017 16:53:49 INFO collection: 'imagine' was found between the indices (94, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'français',\n",
       " 'oui',\n",
       " 'm',\n",
       " 'éveillai',\n",
       " 'étant',\n",
       " 'tchouang',\n",
       " 'tseu',\n",
       " 'suis',\n",
       " 'je',\n",
       " 'réalité',\n",
       " 'qui',\n",
       " 'rêve',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'qui',\n",
       " 's',\n",
       " 'imagine']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(french, expression='\\p{Letter}+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:50 INFO collection: Tokenizing with \\p{Letter}[\\p{Letter}\\p{Punctuation}]*\\p{Letter}|\\p{Letter}{1} ...\n",
      "09-Jan-2017 16:53:50 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'deutsch' was found between the indices (4, 11)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'ja' was found between the indices (14, 16)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'wie' was found between the indices (19, 22)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'geht's' was found between the indices (23, 29)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'ein' was found between the indices (32, 35)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'typisches' was found between the indices (36, 45)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'beispiel' was found between the indices (46, 54)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'für' was found between the indices (56, 59)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'ein' was found between the indices (60, 63)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'system' was found between the indices (64, 70)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'ok' was found between the indices (71, 73)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'verbundenes-wort' was found between the indices (76, 92)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'deutsch',\n",
       " 'ja',\n",
       " 'wie',\n",
       " \"geht's\",\n",
       " 'ein',\n",
       " 'typisches',\n",
       " 'beispiel',\n",
       " 'für',\n",
       " 'ein',\n",
       " 'system',\n",
       " 'ok',\n",
       " 'verbundenes-wort']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(german))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:50 INFO collection: Tokenizing with \\p{Letter}[\\p{Letter}\\p{Punctuation}]*\\p{Letter}|\\p{Letter}{1} ...\n",
      "09-Jan-2017 16:53:50 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'english' was found between the indices (4, 11)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'yes' was found between the indices (14, 17)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'it's' was found between the indices (20, 24)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'the' was found between the indices (26, 29)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'leaf-cutting' was found between the indices (31, 43)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'ant' was found between the indices (44, 47)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'at' was found between the indices (48, 50)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'five' was found between the indices (51, 55)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'o'clock' was found between the indices (56, 63)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'didn't' was found between the indices (65, 71)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'i' was found between the indices (72, 73)\n",
      "09-Jan-2017 16:53:50 INFO collection: 'say' was found between the indices (74, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'english',\n",
       " 'yes',\n",
       " \"it's\",\n",
       " 'the',\n",
       " 'leaf-cutting',\n",
       " 'ant',\n",
       " 'at',\n",
       " 'five',\n",
       " \"o'clock\",\n",
       " \"didn't\",\n",
       " 'i',\n",
       " 'say']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:51 INFO collection: Tokenizing with \\p{Letter}[\\p{Letter}\\p{Punctuation}]*\\p{Letter}|\\p{Letter}{1} ...\n",
      "09-Jan-2017 16:53:51 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'português' was found between the indices (4, 13)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'sim' was found between the indices (16, 19)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'ciência' was found between the indices (23, 30)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'da' was found between the indices (32, 34)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'computação' was found between the indices (35, 45)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'é' was found between the indices (46, 47)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'a' was found between the indices (48, 49)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'ciência' was found between the indices (50, 57)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'que' was found between the indices (58, 61)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'estuda' was found between the indices (62, 68)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'as' was found between the indices (69, 71)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'técnicas' was found between the indices (72, 80)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'classifica-se' was found between the indices (82, 95)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'como' was found between the indices (97, 101)\n",
      "09-Jan-2017 16:53:51 INFO collection: 'ciência' was found between the indices (102, 109)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'português',\n",
       " 'sim',\n",
       " 'ciência',\n",
       " 'da',\n",
       " 'computação',\n",
       " 'é',\n",
       " 'a',\n",
       " 'ciência',\n",
       " 'que',\n",
       " 'estuda',\n",
       " 'as',\n",
       " 'técnicas',\n",
       " 'classifica-se',\n",
       " 'como',\n",
       " 'ciência']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(portuguese))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-Jan-2017 16:53:52 INFO collection: Tokenizing with \\p{Letter}[\\p{Letter}\\p{Punctuation}]*\\p{Letter}|\\p{Letter}{1} ...\n",
      "09-Jan-2017 16:53:52 INFO collection: 'usa' was found between the indices (0, 3)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'español' was found between the indices (4, 11)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'sí' was found between the indices (14, 16)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'de' was found between the indices (20, 22)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'programación' was found between the indices (23, 35)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'y' was found between the indices (37, 38)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'años' was found between the indices (39, 43)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'después' was found between the indices (44, 51)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'del' was found between the indices (52, 55)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'sueño' was found between the indices (56, 61)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'léxico' was found between the indices (62, 68)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'matemático' was found between the indices (70, 80)\n",
      "09-Jan-2017 16:53:52 INFO collection: 'meta-aplicado' was found between the indices (81, 94)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'español',\n",
       " 'sí',\n",
       " 'de',\n",
       " 'programación',\n",
       " 'y',\n",
       " 'años',\n",
       " 'después',\n",
       " 'del',\n",
       " 'sueño',\n",
       " 'léxico',\n",
       " 'matemático',\n",
       " 'meta-aplicado']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.tokenize(spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeder Buchstabe definiert eine bestimmte Kategorie:\n",
    "*  `\\p{L} or \\p{Letter}: any kind of letter from any language.`\n",
    "*  `\\p{P} or \\p{Punctuation}: any kind of punctuation character.`\n",
    "*  `\\p{N} or \\p{Number}: any kind of numeric character in any script.`\n",
    "*  `\\p{S} or \\p{Symbol}: math symbols, currency signs, dingbats, box-drawing characters, etc.`\n",
    "\n",
    "Der englische Ausdruck näher betrachtet:\n",
    "1. `\\p{N}[\\p{N}\\p{P}]*\\p{N}`\n",
    "  *  Eine Zahl (`\\p{N}`), oder keinmal oder mehrmals eine Zahl mit einem punctuation character (`[\\p{N}\\p{P}]*`) verbunden, gefolgt von einer Zahl (`\\p{N}`).\n",
    "    *  z. B. __01.01.2017__ oder __1999__\n",
    "2. `\\p{S}?\\p{N}[\\p{P}\\p{N}]{3}\\p{S}?`\n",
    "  * Keinmal oder einmal ein Symbol (`\\p{S}?`), eine Zahl (`\\p{N}`), ein punctuation character gefolgt von zwei Zahlen (`[\\p{P}\\p{N}]{3}`) und keinmal oder einmal ein Symbol (`\\p{S}`).\n",
    "    * z. B. __€5,99__\n",
    "3. `\\p{L}[\\p{L}\\p{P}]*\\p{L}`\n",
    "  * Ein Buchstabe (`\\p{L}`), keinmal oder mehrmals ein Buchstabe gefolgt von einem punctuation character (`[\\p{L}\\p{P}]*`) und ein Buchstabe (`\\p{L}`).\n",
    "    * z. B. __Hello__ oder __leaf-cutting__\n",
    "4. `\\p{L}{1}`\n",
    "  * Ein einzelner Buchstabe (wird mit 3. nicht gematched!).\n",
    "    * z. B. __a__\n",
    "5. `\\p{N}\\p{L}+`\n",
    "  * Eine Zahl (`\\p{N}`) und ein oder mehrere Buchstaben (`\\p{L}+`).\n",
    "    * z. B. __2nd__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
